{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Remove warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Basic libraries\n",
    "#\n",
    "import time\n",
    "import pandas    as pd\n",
    "import numpy     as np\n",
    "from   tqdm      import tqdm\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Visualization library\n",
    "#\n",
    "import matplotlib.pyplot   as plt \n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Sklearn library\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Tensorflow library\n",
    "#\n",
    "from   tensorflow.keras.models                  import *\n",
    "from   tensorflow.keras.layers                  import *\n",
    "from   tensorflow.keras.callbacks               import *\n",
    "from   tensorflow.keras.metrics                 import *\n",
    "from   tensorflow.keras.optimizers              import *\n",
    "from   tensorflow.keras.utils                   import plot_model\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# User library\n",
    "#\n",
    "from   utils.Evaluation                          import RegressionEvaluation\n",
    "from   utils.LossFunctions                       import *\n",
    "from   utils.CyclicLR                            import *\n",
    "from   utils.WarmUpCosineDecayScheduler          import *\n",
    "from   utils.Attention                           import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#\n",
    "filename   = 'Data/Austin_Weather.csv'\n",
    "\n",
    "# Dictionary with the performance of each model\n",
    "#\n",
    "Performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lag        = 24\n",
    "Horizon    =  3\n",
    "\n",
    "epochs     = 100\n",
    "batch_size =  64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network metrics/loss/optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NN-metrics\n",
    "#\n",
    "metrics = [ MeanAbsolutePercentageError(name=\"MAPE\", dtype=None),\n",
    "            RootMeanSquaredError(name='RMSE', dtype=None) ]\n",
    "\n",
    "# Define Loss function\n",
    "#\n",
    "loss = SMAPE\n",
    "\n",
    "# Define Opitmizer\n",
    "#\n",
    "optimizer = Adam(learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlystopping\n",
    "#\n",
    "earlystopping = EarlyStopping(monitor       = 'val_loss', \n",
    "                              min_delta     = 0,\n",
    "                              patience      = 30,\n",
    "                              verbose       = 1, \n",
    "                              mode          = 'min', \n",
    "                              #\n",
    "                              restore_best_weights = True)\n",
    "  \n",
    "    \n",
    "# Reduce LR on Plateau\n",
    "#\n",
    "lrs_scheduler   = ReduceLROnPlateau(monitor   = 'val_loss', \n",
    "                                   factor     = 0.5,\n",
    "                                   patience   = 5)\n",
    "\n",
    "# Cyclic LR\n",
    "#\n",
    "CyclicLR_scheduler = CyclicLR(base_lr   = 0.001, \n",
    "                              max_lr    = 0.006, \n",
    "                              step_size = 2000., \n",
    "                              mode      = 'triangular')\n",
    "# Cosine Decay\n",
    "#\n",
    "CosLR__scheduler = WarmUpCosineDecayScheduler(learning_rate_base=0.001)\n",
    "\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "#\n",
    "callbacks = [earlystopping, CyclicLR_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "# Load data\n",
    "#\n",
    "df = pd.read_csv( filename )\n",
    "\n",
    "print('[INFO] Data imported')\n",
    "print('[INFO] Time: %.2f seconds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to 'datetime64'\n",
    "#\n",
    "df['Date'] = df['Date'].astype('datetime64')\n",
    "\n",
    "# Set index\n",
    "#\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features based on Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "#\n",
    "Features = ['Temperature [Fahrenheit]', 'DewPoint [Fahrenheit]']\n",
    "\n",
    "# df['DayOfWeek'] = df.index.dayofweek\n",
    "# df['Month']     = df.index.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = int( df.shape[0] * 0.9 )\n",
    "\n",
    "df_train = df[ :idx ]\n",
    "df_test  = df[ idx: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in Features:\n",
    "    \n",
    "    plt.figure( figsize=(20, 2) )\n",
    "    \n",
    "    df_train[feature].plot( color='tab:blue' )\n",
    "    df_test[feature].plot( color='tab:orange')\n",
    "    \n",
    "    plt.legend(['Training', 'Testing'], frameon = False)\n",
    "    plt.ylabel(feature)\n",
    "    plt.title('Feature: {}'.format(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_train.iloc[-Lag:], df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scaler\n",
    "#\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_train = pd.DataFrame( scaler.fit_transform(df_train), \n",
    "                         index   = df_train.index,\n",
    "                         columns = df_train.columns )\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame( scaler.transform(df_test), \n",
    "                        index    = df_test.index,\n",
    "                        columns  = df_test.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training/Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df = None, Lag = 1, Horizon = 12, ForecastingSeries = []):\n",
    "    \n",
    "    if (ForecastingSeries == []):\n",
    "        ForecastingSeries = df.columns\n",
    "    \n",
    "    dataX, dataY = [], []\n",
    "    for i in tqdm( range(df.shape[0] + 1  - Lag - Horizon) ):\n",
    "        \n",
    "        dataX.append( df.to_numpy()[i:(i+Lag)] )        \n",
    "        dataY.append( df[ ForecastingSeries ].to_numpy()[i + Lag : i + Lag + Horizon] )\n",
    "        \n",
    "        \n",
    "    return ( np.array(dataX), np.array(dataY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = create_dataset(df = df_train, \n",
    "                                Lag = Lag, \n",
    "                                Horizon = Horizon, \n",
    "                                ForecastingSeries = Features)\n",
    "\n",
    "testX,  testY  = create_dataset(df = df_test, \n",
    "                                Lag = Lag, \n",
    "                                Horizon = Horizon, \n",
    "                                ForecastingSeries = Features)\n",
    "\n",
    "print('Training instances:   %6i' % trainX.shape[0])\n",
    "print('Testing instances:    %6i' % testX.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(100, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "model.add(RepeatVector( Horizon ))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(trainY.shape[2], activation='linear')))\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/LSTM-AE.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['Seq2Seq LSTM'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_layer = Input(shape=(trainX.shape[1], trainX.shape[2])) \n",
    "\n",
    "conv = Conv1D(filters =  8, kernel_size = 3, activation = 'relu')(Input_layer)\n",
    "conv = Conv1D(filters = 16, kernel_size = 7, activation = 'relu')(conv)\n",
    "\n",
    "lstm = LSTM(100, return_sequences=True, activation='relu')(conv)\n",
    "dropout = Dropout(0.2)(lstm)\n",
    "lstm = LSTM(100, activation='relu')(dropout)\n",
    "\n",
    "dense = Dense(Horizon*trainY.shape[2], activation='relu')(lstm)\n",
    "\n",
    "Output_layer = Reshape((Horizon, trainY.shape[2]))(dense)\n",
    "\n",
    "model = Model([Input_layer], [Output_layer])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/CNN-LSTM.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['CNN-LSTM'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TCN.tcn import *\n",
    "\n",
    "Input_layer = Input(shape=( trainX.shape[1], trainX.shape[2]) )   \n",
    "\n",
    "x = TCN(nb_filters=32, kernel_size=2, padding='same', activation='relu')(Input_layer)\n",
    "#\n",
    "x = Flatten()(x)\n",
    "#\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "x = Dense(Horizon*trainY.shape[2], activation='relu')(x)\n",
    "Output_layer = Reshape((Horizon, trainY.shape[2]))(x)\n",
    "\n",
    "model = Model([Input_layer], [Output_layer])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/TCN.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['TCN'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq CNN-LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Conv1D(filters = 4, kernel_size = 3, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2])) )\n",
    "model.add( Conv1D(filters = 8, kernel_size = 7, activation='relu') )\n",
    "model.add( MaxPooling1D(pool_size=2) )\n",
    "#\n",
    "model.add(Flatten())\n",
    "#\n",
    "model.add( RepeatVector( Horizon ) )\n",
    "model.add( LSTM(200, activation='relu', return_sequences=True) )\n",
    "#\n",
    "model.add(TimeDistributed( Dense(100, activation='relu')) )\n",
    "model.add(TimeDistributed( Dense(trainY.shape[2], activation='linear')) )\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/Seq2Seq-CNN-LSTM.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['Seq2Seq CNN-LSTM'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Head CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_layer = Input(shape=(trainX.shape[1], trainX.shape[2])) \n",
    "\n",
    "head_list = []\n",
    "for i in range(0, trainX.shape[2]):\n",
    "    Conv_layer_head = Conv1D(filters=4, kernel_size=7,  activation='relu')(Input_layer)\n",
    "    Conv_layer_head = Conv1D(filters=6, kernel_size=11, activation='relu')(Conv_layer_head)\n",
    "    Conv_layer_flatten = Flatten()(Conv_layer_head)\n",
    "    head_list.append( Conv_layer_flatten )\n",
    "    \n",
    "    \n",
    "Concat_cnn = Concatenate(axis=1)(head_list)\n",
    "reshape = Reshape((head_list[0].shape[1], trainX.shape[2]))(Concat_cnn)\n",
    "\n",
    "lstm = LSTM(100, activation='relu')(reshape)\n",
    "repeat = RepeatVector( Horizon )(lstm)\n",
    "lstm_2 = LSTM(100, activation='relu', return_sequences=True)(repeat)\n",
    "dropout = Dropout(0.2)(lstm_2)\n",
    "output_layer = Dense(trainY.shape[2], activation='linear')(dropout)\n",
    "\n",
    "model = Model(inputs=Input_layer, outputs=output_layer)\n",
    "\n",
    "    \n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/MultiHead-CNN-LSTM.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['Multi-head CNN-LSTM'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-Att Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_layer = Input(shape=( trainX.shape[1], trainX.shape[2]) )   \n",
    "\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=2, padding='same', activation='relu' )(Input_layer)\n",
    "x = MaxPool1D(2)(x)\n",
    "x = Conv1D(filters=64, kernel_size=2, padding='same', activation='relu' )(x)\n",
    "x = Attention(100)(x)\n",
    "#\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer\n",
    "x = Dense(Horizon*trainY.shape[2], activation='relu')(x)\n",
    "Output_layer = Reshape((Horizon, trainY.shape[2]))(x)\n",
    "\n",
    "model = Model([Input_layer], [Output_layer])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/CNN-Att.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['CNN-Att'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-Att Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb\n",
    "\n",
    "\n",
    "# Inputs\n",
    "#\n",
    "Inputs = Input(shape=(trainX.shape[1], trainX.shape[2]))\n",
    "\n",
    "\n",
    "# Encoder\n",
    "#\n",
    "encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(units = 32, \n",
    "                                                       activation='relu', \n",
    "#                                                        dropout=0.2, \n",
    "#                                                        recurrent_dropout=0.2, \n",
    "                                                       return_sequences=True, \n",
    "                                                       return_state=True)(Inputs)\n",
    "\n",
    "encoder_last_h = BatchNormalization(momentum=0.6)(encoder_last_h)\n",
    "encoder_last_c = BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "\n",
    "\n",
    "# Decoder\n",
    "#\n",
    "decoder_input = RepeatVector( trainY.shape[1] )(encoder_last_h)\n",
    "\n",
    "decoder_stack_h = LSTM(units = 32, \n",
    "                       activation='relu', \n",
    "#                        dropout=0.2, \n",
    "#                        recurrent_dropout=0.2,\n",
    "                       return_state=False, \n",
    "                       return_sequences=True)(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "\n",
    "\n",
    "# Attention\n",
    "#\n",
    "attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "context = dot([attention, encoder_stack_h], axes=[2,1])\n",
    "context = BatchNormalization(momentum=0.6)(context)\n",
    "\n",
    "# Merging\n",
    "#\n",
    "decoder_combined_context = concatenate([context, decoder_stack_h])\n",
    "\n",
    "# Output\n",
    "#\n",
    "# out = Dense( Horizon, activation='linear' )(decoder)\n",
    "Outputs = TimeDistributed(Dense(trainY.shape[2], activation='linear'))(decoder_combined_context)\n",
    "\n",
    "model = Model(inputs = Inputs, outputs = Outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss      = loss, \n",
    "              optimizer = optimizer, \n",
    "              metrics   = metrics)\n",
    "\n",
    "plot_model(model = model, rankdir = \"ΤΒ\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start clock\n",
    "#\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "score = model.fit(trainX, trainY, \n",
    "                  epochs           = epochs, \n",
    "                  batch_size       = batch_size, \n",
    "                  callbacks        = callbacks,\n",
    "                  verbose          = 1, \n",
    "                  validation_split = 0.1)\n",
    "\n",
    "\n",
    "# Terminate clock\n",
    "#\n",
    "print('[INFO] Time = %.2f' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 4))\n",
    "\n",
    "ax[0].plot( score.history['RMSE']     );\n",
    "ax[0].plot( score.history['val_RMSE'] );\n",
    "ax[0].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[0].set_xlabel('Epochs');\n",
    "ax[0].set_ylabel('RMSE');\n",
    "\n",
    "ax[1].plot( score.history['MAPE']     );\n",
    "ax[1].plot( score.history['val_MAPE'] );\n",
    "ax[1].legend(['Training', 'Validation'], frameon=False);\n",
    "ax[1].set_xlabel('Epochs');\n",
    "ax[1].set_ylabel('MAPE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "#\n",
    "model.save('models/LSTM-Att.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict( testX )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Performance on Testing set - Prediction visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, feature in enumerate(Features):\n",
    "    \n",
    "    print('[INFO] Feature: ', feature)\n",
    "    print('------------------------------------------------')\n",
    "    Performance_Foresting_Model = {'RMSE': [], 'MAE': [], 'SMAPE': [], 'R2' : []}\n",
    "\n",
    "    for i in range( Horizon ):\n",
    "    \n",
    "        Prices = pd.DataFrame([])        \n",
    "\n",
    "        Prices['Real']       = testY[:,  i, idx]\n",
    "        Prices['Prediction'] = y_pred[:, i, idx]\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        #\n",
    "        MAE, RMSE, MAPE, SMAPE, R2 = RegressionEvaluation( Prices )\n",
    "        \n",
    "        # Store results\n",
    "        #\n",
    "        Performance_Foresting_Model['RMSE']    += [ RMSE    ]\n",
    "        Performance_Foresting_Model['MAE']     += [ MAE     ]\n",
    "        Performance_Foresting_Model['SMAPE']   += [ SMAPE   ]\n",
    "        Performance_Foresting_Model['R2']      += [ R2      ]\n",
    "        \n",
    "        # Present results\n",
    "        #\n",
    "        print('Horizon: ', i)\n",
    "        print('> RMSE:  ', RMSE)\n",
    "        print('> SMAPE: ', SMAPE)\n",
    "        print('> R2:    ', R2)\n",
    "        print()\n",
    "        \n",
    "Performance['LSTM-Att'] = Performance_Foresting_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPerformance(Metric='RMSE', Performance=None):\n",
    "    \n",
    "    nMethods = len(Performance) \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = nMethods, figsize=(20, 4))\n",
    "    for i, method in enumerate( Performance ):\n",
    "\n",
    "        ax[i].bar(x = np.arange(Horizon)+1, height = Performance[ method ][ Metric ], width = .5 )\n",
    "        ax[i].legend([method], frameon=False)\n",
    "\n",
    "        ax[i].set_ylim([0, np.max(Performance[ method ][ Metric ]) * 1.2])\n",
    "\n",
    "\n",
    "    fig.suptitle('Metric: {}'.format(Metric), size=14);    \n",
    "    fig.text(0.5, -0.1, 'Forecasting horizon', ha='center', size=14);\n",
    "    fig.text(0.08, 0.5, Metric, va='center', rotation='vertical', size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPerformance('RMSE', Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPerformance('SMAPE', Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPerformance('R2', Performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-dev_ili_v1] *",
   "language": "python",
   "name": "conda-env-.conda-dev_ili_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
